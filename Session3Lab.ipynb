{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!apt-get update && apt-get install -y build-essential\r\n",
    "!pip install xgboost\r\n",
    "!pip install shap"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import xgboost as xgb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "def prepare_data(data, target):\r\n",
    "    X = data.drop(target, axis=1)\r\n",
    "    y = data[target]\r\n",
    "\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\r\n",
    "\r\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_confusion_matrix, roc_auc_score\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def evaluate(model, X_test, y_test):\r\n",
    "    pred = model.predict(X_test)\r\n",
    "    # accuracy = correct_predictions / all_predictions \r\n",
    "    acc = accuracy_score(y_test, pred)\r\n",
    "\r\n",
    "    # true_positives / (true_positives + false_postives)\r\n",
    "    # how many positive predictions were true\r\n",
    "    prec = precision_score(y_test, pred, average='weighted')\r\n",
    "\r\n",
    "    # true_postives / (true_positives + false_negatives)\r\n",
    "    # how many postives out of all were identified\r\n",
    "    rec = recall_score(y_test, pred, average='weighted')\r\n",
    "\r\n",
    "    # harmonic mean of precision and recall\r\n",
    "    f1 = f1_score(y_test, pred, average='weighted')\r\n",
    "    \r\n",
    "    print(f\"accuracy: {acc}\")\r\n",
    "    print(f\"precision: {prec}\")\r\n",
    "    print(f\"recall: {rec}\")\r\n",
    "    print(f\"f1: {f1}\")\r\n",
    "    \r\n",
    "    try:\r\n",
    "        prob = model.predict_proba(X_test)\r\n",
    "        roc_auc = roc_auc_score(y_test, prob, multi_class='ovo')\r\n",
    "        print(f\"roc_auc: {roc_auc}\")\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "    \r\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\r\n",
    "    plot_confusion_matrix(model, X_test, y_test, xticks_rotation='vertical', ax=ax)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binary Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "heart_data = pd.read_csv('heart.csv')\r\n",
    "heart_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(heart_data, 'target')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "model = LogisticRegression()\r\n",
    "model.fit(X_train, y_train)\r\n",
    "evaluate(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred = model.predict(X_test)\r\n",
    "false_positives = 0\r\n",
    "false_negatives = 0\r\n",
    "for prediction, truth in zip(pred, y_test):\r\n",
    "    if truth == 1 and prediction == 0:\r\n",
    "        false_negatives += 1\r\n",
    "    if truth == 0 and prediction == 1:\r\n",
    "        false_positives += 1\r\n",
    "\r\n",
    "print(f\"False Positives: {false_positives}\")\r\n",
    "print(f\"False negatives {false_negatives}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import roc_curve, plot_roc_curve\r\n",
    "roc_curve(y_test, model.predict_proba(X_test)[:,1])\r\n",
    "plot_roc_curve(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification (Crop Recommendation)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "crop_data = pd.read_csv('crops.csv')\r\n",
    "crop_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(crop_data, 'label')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "model = GaussianNB()\r\n",
    "model.fit(X_train, y_train)\r\n",
    "evaluate(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sochastic Gradient Descent Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import SGDClassifier\r\n",
    "model = SGDClassifier()\r\n",
    "model.fit(X_train, y_train)\r\n",
    "evaluate(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perceptron Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import Perceptron\r\n",
    "model = Perceptron()\r\n",
    "model.fit(X_train, y_train)\r\n",
    "evaluate(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "model = DecisionTreeClassifier()\r\n",
    "model.fit(X_train, y_train)\r\n",
    "evaluate(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = xgb.XGBClassifier()\r\n",
    "model.fit(X_train, y_train)\r\n",
    "evaluate(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "house_data = pd.read_csv('house_prices.csv')\r\n",
    "house_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Categorical Encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "house_data = house_data.drop(['date', 'country'], axis=1)\r\n",
    "house_data['street'] = house_data['street'].apply(lambda x: ' '.join(x.split(' ')[1:]))\r\n",
    "\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "street_encoder = LabelEncoder()\r\n",
    "house_data['street'] = street_encoder.fit_transform(house_data['street'])\r\n",
    "\r\n",
    "city_encoder = LabelEncoder()\r\n",
    "house_data['city'] = city_encoder.fit_transform(house_data['city'])\r\n",
    "\r\n",
    "zip_encoder = LabelEncoder()\r\n",
    "house_data['statezip'] = zip_encoder.fit_transform(house_data['statezip'])\r\n",
    "\r\n",
    "house_data\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(house_data, 'price')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\r\n",
    "model = LinearRegression()\r\n",
    "model.fit(X_train, y_train)\r\n",
    "pred = model.predict(X_test)\r\n",
    "mae = mean_absolute_error(y_test, pred)\r\n",
    "mse = mean_squared_error(y_test, pred)\r\n",
    "rmse = mean_squared_error(y_test, pred, squared=False)\r\n",
    "\r\n",
    "print(f\"Mean absolute error: {mae}\")\r\n",
    "print(f\"Mean squared error: {mse}\")\r\n",
    "print(f\"Root mean squared error: {rmse}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "param_grid = {\r\n",
    "    \"penalty\": ['l1', 'l2', 'elasticnet'],\r\n",
    "    \"alpha\": [0.0001, 0.001, 0.01],\r\n",
    "    \"eta0\": [0.001, 0.01, 0.1],\r\n",
    "    \"learning_rate\": ['constant', 'adaptive']\r\n",
    "}\r\n",
    "grid_cv = GridSearchCV(SGDClassifier(), param_grid, n_jobs=-1, cv=5, scoring=\"f1_weighted\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_cv.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_cv.best_score_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_cv.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = grid_cv.best_estimator_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "evaluate(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Scaling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Prep"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(crop_data, 'label')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
    "\r\n",
    "X = crop_data.drop(\"label\", axis=1)\r\n",
    "y = crop_data[\"label\"]\r\n",
    "\r\n",
    "standard_scaler = StandardScaler()\r\n",
    "standard_scaler.fit(X)\r\n",
    "X_s_scaled = pd.DataFrame(standard_scaler.transform(X), columns=X.columns)\r\n",
    "\r\n",
    "minmax_scaler = MinMaxScaler()\r\n",
    "minmax_scaler.fit(X)\r\n",
    "X_mm_scaled = pd.DataFrame(minmax_scaler.transform(X), columns=X.columns)\r\n",
    "with pd.option_context('display.float_format', lambda x: '%.3f' % x):  \r\n",
    "    print(\"Unscaled Data:\") \r\n",
    "    display(X.describe())\r\n",
    "    print(\"Standardized Data:\")\r\n",
    "    display(X_s_scaled.describe())\r\n",
    "    print(\"Normalized Data:\")\r\n",
    "    display(X_mm_scaled.describe())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unscaled Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
    "model = SGDClassifier()\r\n",
    "model.fit(X_train, y_train)\r\n",
    "evaluate(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standardized Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_s_scaled, y, test_size=0.2, random_state=42)\r\n",
    "model = SGDClassifier()\r\n",
    "model.fit(X_train, y_train)\r\n",
    "evaluate(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalized Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_mm_scaled, y, test_size=0.2, random_state=42)\r\n",
    "model = SGDClassifier()\r\n",
    "model.fit(X_train, y_train)\r\n",
    "evaluate(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SHAP Values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import shap"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(crop_data, 'label')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = xgb.XGBClassifier()\r\n",
    "model.fit(X_train, y_train)\r\n",
    "evaluate(model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "explainer = shap.Explainer(model, X_train)\r\n",
    "shap_values = explainer(X_train)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('AWS': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "interpreter": {
   "hash": "5548450a1352afa305e3f4a4f6905490e400aa9dcb629f43c17cbb102a731220"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}